# RGB2HSI MultimodalCLIP - å¤šæ¨¡æ€å›¾åƒè½¬æ¢æ¨¡å‹

ä¸€ä¸ªç±»ä¼¼CLIPçš„å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ é¡¹ç›®ï¼Œç”¨äºRGBå›¾åƒåˆ°é«˜å…‰è°±å›¾åƒ(HSI)çš„è½¬æ¢ã€‚æ”¯æŒæœ‰ç›‘ç£ã€è‡ªç›‘ç£å’Œæ— ç›‘ç£å­¦ä¹ ã€‚

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

### æ ¸å¿ƒåŠŸèƒ½
- **RGBâ†’HSIè½¬æ¢**: å°†æ™®é€šRGBå½©è‰²å›¾åƒè½¬æ¢ä¸º31é€šé“çš„é«˜å…‰è°±å›¾åƒ
- **å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ **: ç±»ä¼¼CLIPçš„æ–¹å¼å­¦ä¹ è·¨æ¨¡æ€è¡¨ç¤º
- **çµæ´»çš„å­¦ä¹ æ¨¡å¼**:
  - æœ‰é…å¯¹æ•°æ®çš„ç›‘ç£å­¦ä¹ 
  - æ— é…å¯¹æ•°æ®çš„è‡ªç›‘ç£å­¦ä¹ 
  - æ··åˆå­¦ä¹ ç­–ç•¥

### åº”ç”¨åœºæ™¯
- é¥æ„Ÿå›¾åƒå¤„ç†
- åŒ»å­¦æˆåƒ
- ææ–™ç§‘å­¦æ£€æµ‹
- å†œä¸šç›‘æµ‹
- æ–‡åŒ–é—äº§ä¿æŠ¤

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

```
RGB2HSI-MultimodalCLIP
â”œâ”€â”€ main.py                    # è®­ç»ƒå…¥å£
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml          # è®­ç»ƒé…ç½®
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ rgb_encoder.py    # RGBç¼–ç å™¨ (ResNetç³»åˆ—)
â”‚   â”‚   â”œâ”€â”€ hsi_encoder.py    # HSIç¼–ç å™¨ (SpectralUNet)
â”‚   â”‚   â”œâ”€â”€ decoder.py        # å…‰è°±è§£ç å™¨
â”‚   â”‚   â””â”€â”€ rgb2hsi_model.py  # ä¸»æ¨¡å‹
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â””â”€â”€ fusion.py         # è·¨æ¨¡æ€èåˆæ¨¡å—
â”‚   â”œâ”€â”€ losses/
â”‚   â”‚   â””â”€â”€ hybrid_loss.py    # æ··åˆCLIPæŸå¤±
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”œâ”€â”€ pair_datasets.py  # æˆå¯¹æ•°æ®é›†
â”‚   â”‚   â”œâ”€â”€ unpaired_rgb.py   # æ— é…å¯¹RGBæ•°æ®
â”‚   â”‚   â””â”€â”€ unpaired_hsi.py   # æ— é…å¯¹HSIæ•°æ®
â”‚   â”œâ”€â”€ trainers/
â”‚   â”‚   â””â”€â”€ trainer.py        # è®­ç»ƒå™¨
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ inference.py      # æ¨ç†å·¥å…·
â”‚       â””â”€â”€ metrics.py        # è¯„ä¼°æŒ‡æ ‡
â”œâ”€â”€ checkpoints/              # æ¨¡å‹æ£€æŸ¥ç‚¹
â”œâ”€â”€ logs/                      # è®­ç»ƒæ—¥å¿—
â””â”€â”€ results/                   # æ¨ç†ç»“æœ
```

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### ç¼–ç å™¨è®¾è®¡

#### RGBç¼–ç å™¨
- æ”¯æŒå¤šç§éª¨å¹²ç½‘ç»œ: ResNet18, ResNet50, ResNet101
- é¢„è®­ç»ƒæƒé‡åˆå§‹åŒ–
- ç‰¹å¾æŠ•å½±åˆ°ç»Ÿä¸€ç»´åº¦

#### HSIç¼–ç å™¨ (SpectralUNet)
- U-Netæ¶æ„æ”¯æŒå¤šå°ºåº¦ç‰¹å¾æå–
- è·³è·ƒè¿æ¥ä¿ç•™ç»†èŠ‚ä¿¡æ¯
- å…¨å±€å¹³å‡æ± åŒ–å’ŒæŠ•å½±å¤´

### èåˆæ¨¡å— (CLIP-Style)
- å¤šå¤´äº¤å‰æ³¨æ„åŠ›æœºåˆ¶
- RGBç‰¹å¾å…³æ³¨HSIç‰¹å¾çš„å¼•å¯¼
- å¤šå±‚äº¤å‰èåˆå †å 
- è‡ªæ³¨æ„åŠ› + äº¤å‰æ³¨æ„åŠ› + MLP

### æŸå¤±å‡½æ•°

#### 1. é‡å»ºæŸå¤± (Reconstruction Loss)
```
L_recon = 0.7 * L1 + 0.3 * MSE
```

#### 2. å¯¹æ¯”å­¦ä¹ æŸå¤± (NT-Xent)
```
L_contrastive = CrossEntropyLoss(RGBâ†’HSI) + CrossEntropyLoss(HSIâ†’RGB)
```

#### 3. å…‰è°±çº¦æŸæŸå¤±
- å…‰è°±å¹³æ»‘æ€§: é¼“åŠ±ç›¸é‚»å…‰è°±é€šé“çš„è¿ç»­æ€§
- å…‰è°±å…ˆéªŒ: åˆ©ç”¨HSIçš„ç»Ÿè®¡ç‰¹æ€§

#### 4. æ€»ä½“æŸå¤±
```
L_total = Î±Â·L_recon + Î²Â·L_contrastive + Î³Â·L_spectral + Î´Â·L_prior
```

### æ··åˆç²¾åº¦è®­ç»ƒ
- æ”¯æŒè‡ªåŠ¨æ··åˆç²¾åº¦(AMP)åŠ é€Ÿ
- æ¢¯åº¦ç´¯ç§¯å¤„ç†å¤§æ‰¹é‡
- å­¦ä¹ ç‡é¢„çƒ­å’Œä½™å¼¦é€€ç«è°ƒåº¦

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè®¾ç½®

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n rgb2hsi python=3.10
conda activate rgb2hsi

# å®‰è£…ä¾èµ–
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install PyYAML numpy pillow scikit-image scipy tensorboard
```

### æ•°æ®å‡†å¤‡

æ•°æ®ç›®å½•ç»“æ„:
```
data/
â”œâ”€â”€ real_pair/
â”‚   â”œâ”€â”€ rgb/          # RGB JPG/PNG å›¾åƒ
â”‚   â””â”€â”€ hsi/          # HSI .npy æ–‡ä»¶ (H, W, 31)
â”œâ”€â”€ synthetic_pair/
â”‚   â”œâ”€â”€ rgb/
â”‚   â””â”€â”€ hsi/
â”œâ”€â”€ unpaired_rgb/     # RGBåªæœ‰å›¾åƒ
â””â”€â”€ unpaired_hsi/     # HSIåªæœ‰å›¾åƒ
```

### è®­ç»ƒ

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python main.py

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python main.py --config configs/custom.yaml
```

### æ¨ç†

```python
from src.models.rgb2hsi_model import RGB2HSIModel
from src.utils.inference import RGB2HSIInference
import yaml

# åŠ è½½é…ç½®å’Œæ¨¡å‹
with open('configs/default.yaml') as f:
    config = yaml.safe_load(f)

model = RGB2HSIModel(config)
model.load_state_dict(torch.load('checkpoints/model_final.pth'))

# åˆ›å»ºæ¨ç†å™¨
inferencer = RGB2HSIInference(model, config)

# å•å¼ å›¾åƒæ¨ç†
pred_hsi, rgb_proj = inferencer.inference('path/to/image.jpg')

# ä¿å­˜ç»“æœ
inferencer.save_hsi(pred_hsi, 'results/output.npy')
```

## ğŸ“Š é…ç½®è¯´æ˜

ä¸»è¦é…ç½®é¡¹åœ¨ `configs/default.yaml`:

### æ¨¡å‹é…ç½®
```yaml
model:
  rgb_encoder:
    name: "ResNet50"        # ç¼–ç å™¨ç±»å‹
    pretrained: true        # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
    hidden_dim: 512         # ç‰¹å¾ç»´åº¦
  
  hsi_encoder:
    name: "SpectralUNet"
    hidden_dim: 256
    num_layers: 4           # U-Netå±‚æ•°
  
  fusion_module:
    num_heads: 8            # æ³¨æ„åŠ›å¤´æ•°
    num_layers: 3           # èåˆå±‚æ•°
  
  embedding_dim: 256        # æŠ•å½±åµŒå…¥ç»´åº¦
```

### è®­ç»ƒé…ç½®
```yaml
training:
  epochs: 200
  batch_size: 32
  lr: 1e-4
  gradient_accumulation_steps: 4  # æ¢¯åº¦ç´¯ç§¯
  mixed_precision: false          # æ··åˆç²¾åº¦
```

### æŸå¤±æƒé‡
```yaml
loss:
  weights:
    l1: 1.0                 # L1é‡å»ºæŸå¤±
    spectral: 1.0           # å…‰è°±çº¦æŸ
    perceptual: 0.5         # æ„ŸçŸ¥æŸå¤±
    contrastive: 1.0        # å¯¹æ¯”å­¦ä¹ 
    reconstruction: 1.0     # é‡å»ºæŸå¤±
```

## ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡

- **MSE** (Mean Squared Error): å‡æ–¹è¯¯å·®
- **PSNR** (Peak Signal-to-Noise Ratio): å³°å€¼ä¿¡å™ªæ¯”
- **SSIM** (Structural Similarity): ç»“æ„ç›¸ä¼¼åº¦
- **SAM** (Spectral Angle Mapper): å…‰è°±è§’åˆ¶å›¾
- **ERGAS** (Erreur Relative Globale Adimensionnelle): ç›¸å¯¹æ— ç»´æ•°è¯¯å·®

```python
from src.utils.metrics import MetricsCalculator

metrics = MetricsCalculator(['mse', 'psnr', 'ssim', 'sam'])
results = metrics.compute(pred_hsi, gt_hsi)
print(results)
```

## ğŸ¯ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰ç¼–ç å™¨

```python
from src.models.rgb_encoder import RGBEncoder

# ä½¿ç”¨ResNet101
config = {
    "name": "ResNet101",
    "pretrained": True,
    "hidden_dim": 512,
}
encoder = RGBEncoder(config)
```

### è‡ªå®šä¹‰èåˆæ¨¡å—

```python
from src.modules.fusion import CrossAttentionFusionModule

config = {
    "dim": 512,
    "num_heads": 8,
    "num_layers": 5,  # å¢åŠ æ›´å¤šå±‚
    "dropout": 0.1,
}
fusion = CrossAttentionFusionModule(config)
```

### ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

```python
from src.trainers.trainer import Trainer

trainer = Trainer(config)
trainer.load_checkpoint('checkpoints/epoch_50.pth')
trainer.train()  # ä»ç¬¬51ä¸ªepochç»§ç»­
```

## ğŸ”¬ ç ”ç©¶æ‰©å±•

### å¯èƒ½çš„æ”¹è¿›æ–¹å‘

1. **æ¶æ„ä¼˜åŒ–**
   - ä½¿ç”¨Vision Transformer (ViT)æ›¿ä»£CNN
   - å¼•å…¥å›¾åƒæ–‡æœ¬å¯¹æ¯” (å¦‚æœæœ‰æ–‡æœ¬æ ‡æ³¨)
   - å¤šå°ºåº¦èåˆé‡‘å­—å¡”

2. **æŸå¤±å‡½æ•°**
   - å¼•å…¥æ„ŸçŸ¥æŸå¤± (LPIPS)
   - å¯¹æŠ—æ€§æŸå¤± (GAN)
   - å…‰è°±é‡å»ºçš„æ ‡å‡†åŒ–æŒ‡æ ‡

3. **è®­ç»ƒç­–ç•¥**
   - è¯¾ç¨‹å­¦ä¹  (ä»ç®€å•åˆ°å¤æ‚)
   - è‡ªé€‚åº”æƒé‡è°ƒæ•´
   - å…ƒå­¦ä¹ ä¼˜åŒ–

4. **æ•°æ®å¢å¼º**
   - å…‰è°±è§’åº¦çš„éšæœºå˜æ¢
   - æ··åˆæ‰¹æ¬¡å¢å¼º (MixUp/CutMix)
   - è‡ªé€‚åº”å¢å¼º

**æœ€åæ›´æ–°**: 2025-12-09
**ç‰ˆæœ¬**: 1.0.0
